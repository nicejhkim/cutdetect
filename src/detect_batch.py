import json
import shutil
import os, sys
from common import utils
from frame import frames, clip, yolo
from scene import cut, split

from rich.panel import Panel
from rich import print as rprint

# ì‚¬ìš©í•  sceneì˜ ìµœì†Œ, ìµœëŒ€ ê¸¸ì´
MIN_SEC = 5.0
MAX_SEC = 10.0

PROMPTS = [
    "a photo of a building exterior",
    "a tall skyscraper",
    "an old temple building exterior",
    "cityscape"
    "a road",
    "a road with cars",
    "a road with buildings",
    "a mountain landscape",
    "a beach or sea",
    "a river",
    "a field"
]
CLIP_THRESHOLD = 0.7

VIDEO_PATH = "samples/sinkhole.mp4"
CONFIG = {
    'FRAMES_DIR': "frames_{}",
    'SCENES_DIR': "scenes_{}",
    'DETECTION_LOG': "results_{}.json"
}

def process(input_file: str):
    #1. ì”¬ ë‹¨ìœ„ ì •ë³´ 
    scenes = utils.measure_time('detect_scenes', split.split_scenes_scenedetect, input_file)
    rprint(Panel(f"[green]ğŸ” ì´ ê°ì§€ëœ ì”¬ ìˆ˜: {len(scenes)}[/green]"))

    results = []
    scene_paths = []    # blur ì²˜ë¦¬ í•  scene íŒŒì¼ëª…
    cut_tasks = []      # ì˜ë¯¸ ìˆëŠ” ê²ƒìœ¼ë¡œ íŒëª…ëœ, ì˜ë¼ë‚¼ ì”¬ ì •ë³´

    #2. ê° ì”¬ì— ëŒ€í•´ 
    for i, (start, end) in enumerate(scenes):
        start_sec = start.get_seconds()
        end_sec = end.get_seconds()
        duration = end_sec - start_sec

        start_frame = start.get_frames()
        end_frame = end.get_frames()

        result = {
            'scene_id': i,
            'start_time': start_sec,
            'end_time': end_sec,
            'duration': duration,
            'start_frame': start_frame,
            'end_frame': end_frame
        }

        #3. ê¸¸ì´ í™•ì¸
        if duration < MIN_SEC or duration > MAX_SEC:
            result['error'] = 'invalid length'
        else:
            #4. ì¤‘ê°„ í”„ë ˆì„ ì¶”ì¶œ
            mid_sec = (start_sec + end_sec) / 2
            frame = utils.measure_time('extract_frame', frames.extract_frame, input_file, mid_sec)
            if frame is None:
                result['error'] = 'failed to extract frame'
            else:
                #5. ì¶”ì¶œí•œ í”„ë ˆì„ íŒŒì¼ë¡œ ì €ì¥
                frame_path = os.path.join(CONFIG['frames_dir'], f"frame_{i}.png")
                utils.measure_time('save_frame', frames.save_frame, frame, frame_path)

                #6. CLIP ëª¨ë¸ ì´ìš©í•´ì„œ í”„ë ˆì„ ì‹ë³„
                probs = utils.measure_time('classify_with_clip', clip.classify_with_clip, frame, PROMPTS)
                best_label, best_prob = clip.get_best_from_probs(probs, PROMPTS)
                probs_f = [t.tolist() for t in probs]
                result.update({
                    'probs': probs_f,
                    'best_label': best_label,
                    'best_prob': float(best_prob),
                })

                print(f"[{i:03d}] Top match: {best_label} ({best_prob:.2%})")

                if best_prob > CLIP_THRESHOLD:

                    # 7. YOLO_face ëª¨ë¸ ì´ìš©í•´ì„œ í™”ë©´ì— ì‚¬ëŒì´ ë„ˆë¬´ í¬ê²Œ ë‚˜ì˜¤ì§€ ì•ŠëŠ”ì§€ íŒë…
                    yolo_results = utils.measure_time('detect_labels_with_yolo', yolo.detect_labels_with_yolo, frame)
                    result['yolo_labels'] = [yolo_results.names[int(box.cls[0])] for box in yolo_results.boxes]
                    too_large_person = yolo.detect_too_large_person(frame, yolo_results, 0.2)

                    frame_person = yolo.draw_person_boxes(frame, yolo_results)
                    frames.save_frame(frame_person, os.path.join(CONFIG['frames_dir'], f"frame_{i}_person.png"))

                    if too_large_person:
                        result['error'] = 'too large person'
                else:
                    result['error'] = 'clip did not detect'
                    
        if 'error' not in result:
            output_path = os.path.join(CONFIG['scenes_dir'], f"scene_{i:03d}.mp4")
            scene_paths.append(output_path)
            cut_tasks.append((input_file, start_sec, end_sec, output_path))

        results.append(result)

    utils.measure_time('cut_scenes', cut.cut_video_ffmpeg_parallel, cut_tasks)
    utils.measure_time('blur_scenes', yolo.blur_yolo_parallel, scene_paths)

    utils.print_summary()

    # ê²°ê³¼ jsonìœ¼ë¡œ ì €ì¥
    with open(CONFIG['detection_log'], 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    input_file = sys.argv[1] if len(sys.argv) > 1 else VIDEO_PATH
    if not os.path.isfile(input_file):
        print(f"â— íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {input_file}")
        sys.exit(1)

    base_name = utils.get_base_name(input_file)

    CONFIG['frames_dir'] = CONFIG['FRAMES_DIR'].format(base_name) # ì¸ì‹í•  frame ì €ì¥ ê²½ë¡œ
    CONFIG['scenes_dir'] = CONFIG['SCENES_DIR'].format(base_name) # ë¶„ë¦¬í•œ clip ì €ì¥ ê²½ë¡œ
    CONFIG['detection_log'] = CONFIG['DETECTION_LOG'].format(base_name)

    for folder in [CONFIG['frames_dir'], CONFIG['scenes_dir']]:
        if os.path.exists(folder):
            shutil.rmtree(folder)
        os.makedirs(folder)

    # ì‘ì—… ì¤€ë¹„ ë.
    process(input_file)